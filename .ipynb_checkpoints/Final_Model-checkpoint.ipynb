{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6438b618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boramert/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Users/boramert/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc371a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_infs(ds):\n",
    "    ds.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    ds.dropna(how='any', inplace=True)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fbcb179",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      "    Destination Port   Flow Duration   Total Fwd Packets  \\\n",
      "0              49188               4                   2   \n",
      "1              49188               1                   2   \n",
      "2              49188               1                   2   \n",
      "3              49188               1                   2   \n",
      "4              49486               3                   2   \n",
      "\n",
      "    Total Backward Packets  Total Length of Fwd Packets  \\\n",
      "0                        0                           12   \n",
      "1                        0                           12   \n",
      "2                        0                           12   \n",
      "3                        0                           12   \n",
      "4                        0                           12   \n",
      "\n",
      "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
      "0                             0                       6   \n",
      "1                             0                       6   \n",
      "2                             0                       6   \n",
      "3                             0                       6   \n",
      "4                             0                       6   \n",
      "\n",
      "    Fwd Packet Length Min   Fwd Packet Length Mean   Fwd Packet Length Std  \\\n",
      "0                       6                      6.0                     0.0   \n",
      "1                       6                      6.0                     0.0   \n",
      "2                       6                      6.0                     0.0   \n",
      "3                       6                      6.0                     0.0   \n",
      "4                       6                      6.0                     0.0   \n",
      "\n",
      "   ...   min_seg_size_forward  Active Mean   Active Std   Active Max  \\\n",
      "0  ...                     20          0.0          0.0            0   \n",
      "1  ...                     20          0.0          0.0            0   \n",
      "2  ...                     20          0.0          0.0            0   \n",
      "3  ...                     20          0.0          0.0            0   \n",
      "4  ...                     20          0.0          0.0            0   \n",
      "\n",
      "    Active Min  Idle Mean   Idle Std   Idle Max   Idle Min   Label  \n",
      "0            0        0.0        0.0          0          0  BENIGN  \n",
      "1            0        0.0        0.0          0          0  BENIGN  \n",
      "2            0        0.0        0.0          0          0  BENIGN  \n",
      "3            0        0.0        0.0          0          0  BENIGN  \n",
      "4            0        0.0        0.0          0          0  BENIGN  \n",
      "\n",
      "[5 rows x 79 columns]\n",
      "____________________________________________ \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get dataset\n",
    "\n",
    "dataset = pd.read_csv(\"test_dataset.csv\")\n",
    "print(\"Dataset:\")\n",
    "print(dataset.head())\n",
    "print(\"____________________________________________ \\n \\n\")\n",
    "\n",
    "dataset = drop_infs(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6bb4397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2827876, 79)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15576b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Labels:\n",
      "['BENIGN' 'DDoS' 'PortScan' 'Bot' 'Infiltration'\n",
      " 'Web Attack � Brute Force' 'Web Attack � XSS'\n",
      " 'Web Attack � Sql Injection' 'FTP-Patator' 'SSH-Patator' 'DoS slowloris'\n",
      " 'DoS Slowhttptest' 'DoS Hulk' 'DoS GoldenEye' 'Heartbleed']\n",
      "____________________________________________\n",
      "Encoded Labels:\n",
      "[ 0  2 10  1  9 12 14 13  7 11  6  5  4  3  8]\n",
      "____________________________________________ \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = dataset[' Label'].copy()\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "labels_encoded = le.fit_transform(labels)\n",
    "labels_encoded = pd.DataFrame(labels_encoded, columns=[' Label'])\n",
    "labels_encoded = labels_encoded[' Label'].copy()\n",
    "\n",
    "print(\"Data Labels:\")\n",
    "print(labels.unique())\n",
    "print(\"____________________________________________\")\n",
    "\n",
    "print(\"Encoded Labels:\")\n",
    "print(labels_encoded.unique())\n",
    "print(\"____________________________________________ \\n \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e3b98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataseti x ve y olarak ayırma\n",
    "y = labels_encoded\n",
    "x = dataset.drop(' Label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "860cfa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizasyon\n",
    "scaler = preprocessing.StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5fbd7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 08:54:53.743452: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "x_train = np.asarray(x_scaled).astype(np.float32)\n",
    "\n",
    "x_train = tf.cast(x_train, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be19816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Sequential()\n",
    "autoencoder.add(Dense(32, activation='relu', input_shape=(78,)))\n",
    "autoencoder.add(Dense(16, activation='relu'))\n",
    "autoencoder.add(Dense(8, activation='linear', name=\"Compressed\"))\n",
    "autoencoder.add(Dense(16, activation='relu'))\n",
    "autoencoder.add(Dense(32, activation='relu'))\n",
    "autoencoder.add(Dense(78, activation='sigmoid'))\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "513f8953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Autoencoder...\n",
      "Epoch 1/10\n",
      "28279/28279 [==============================] - 26s 914us/step - loss: 0.6854 - val_loss: 0.6054\n",
      "Epoch 2/10\n",
      "28279/28279 [==============================] - 23s 801us/step - loss: 0.6734 - val_loss: 0.6051\n",
      "Epoch 3/10\n",
      "28279/28279 [==============================] - 23s 804us/step - loss: 0.6724 - val_loss: 0.6044\n",
      "Epoch 4/10\n",
      "28279/28279 [==============================] - 23s 816us/step - loss: 0.6719 - val_loss: 0.6047\n",
      "Epoch 5/10\n",
      "28279/28279 [==============================] - 23s 822us/step - loss: 0.6718 - val_loss: 0.6040\n",
      "Epoch 6/10\n",
      "28279/28279 [==============================] - 24s 858us/step - loss: 0.6716 - val_loss: 0.6039\n",
      "Epoch 7/10\n",
      "28279/28279 [==============================] - 23s 796us/step - loss: 0.6712 - val_loss: 0.6038\n",
      "Epoch 8/10\n",
      "28279/28279 [==============================] - 23s 796us/step - loss: 0.6708 - val_loss: 0.6039\n",
      "Epoch 9/10\n",
      "28279/28279 [==============================] - 23s 798us/step - loss: 0.6707 - val_loss: 0.6037\n",
      "Epoch 10/10\n",
      "28279/28279 [==============================] - 22s 795us/step - loss: 0.6705 - val_loss: 0.6036\n",
      "Training Complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Autoencoder...\")\n",
    "history = autoencoder.fit(x_train,\n",
    "                          x_train,\n",
    "                          batch_size=80,\n",
    "                          epochs=10,\n",
    "                          verbose=1,\n",
    "                          validation_split=0.2)\n",
    "print(\"Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0179b2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Encoded Data...\n",
      "88372/88372 [==============================] - 30s 333us/step\n",
      "Encoding Complete.\n"
     ]
    }
   ],
   "source": [
    "encoder = Model(autoencoder.input, autoencoder.get_layer('Compressed').output)\n",
    "\n",
    "encoder.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "print(\"Creating Encoded Data...\")\n",
    "encoded_x = encoder.predict(x_train)\n",
    "print(\"Encoding Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6ce4ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(encoded_x, y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=12345,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9630f5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "model_xgb = xgb.XGBClassifier(n_estimators=100, max_depth=1, learning_rate=0.2, verbosity=1,\n",
    "                              use_label_encoder=False,\n",
    "                              eval_metric='merror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb12653c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Cross Validation:\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBoost Cross Validation:\")\n",
    "cv = RepeatedStratifiedKFold(n_splits=8, random_state=12345)\n",
    "n_scores = cross_val_score(model_xgb, x_train, y_train, scoring='accuracy', cv=cv, error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe674279",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "print(\"____________________________________________ \\n \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"XGBoost Training....\")\n",
    "model_xgb.fit(x_train, y_train)\n",
    "xgb_preds = model_xgb.predict(x_test)\n",
    "print(\"Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26cb753",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"XGBoost Score:\")\n",
    "model_xgb.score(x_test, y_test)\n",
    "print(\"____________________________________________ \\n \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ee8f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First training\n",
    "print(\"Benign - Attack Classification\")\n",
    "print(\"\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, xgb_preds))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, xgb_preds))\n",
    "print(\"____________________________________________ \\n \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37913a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = le.inverse_transform(y)\n",
    "conf_matrix = confusion_matrix(y_test, xgb_preds)\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS,\n",
    "            yticklabels=LABELS, annot=True, fmt=\"d\")\n",
    "plt.title(\"Benign - Attack Classification\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31f630d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
