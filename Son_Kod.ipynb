{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "316ab2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boramert/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Users/boramert/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf7356b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_infs(ds):\n",
    "    ds.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    ds.dropna(how='any', inplace=True)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a3c5d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset...\n",
      "Dataset Loaded.\n",
      "_____________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Dataset...\")\n",
    "dataset = pd.read_csv(\"test_dataset.csv\")\n",
    "dataset = drop_infs(dataset)\n",
    "print(\"Dataset Loaded.\")\n",
    "print(\"_____________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39ac1980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "['BENIGN' 'Bot' 'DDoS' 'DoS GoldenEye' 'DoS Hulk' 'DoS Slowhttptest'\n",
      " 'DoS slowloris' 'FTP-Patator' 'Heartbleed' 'Infiltration' 'PortScan'\n",
      " 'SSH-Patator' 'Web Attack � Brute Force' 'Web Attack � Sql Injection'\n",
      " 'Web Attack � XSS']\n",
      "_____________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "labels = dataset[' Label'].copy()\n",
    "print(\"Labels:\")\n",
    "print(np.unique(labels))\n",
    "print(\"_____________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15b37527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels for XGBoost Classification:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "_____________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xgb_labels = dataset[' Label'].copy()\n",
    "le = preprocessing.LabelEncoder()\n",
    "xgb_labels = le.fit_transform(xgb_labels)\n",
    "print(\"Labels for XGBoost Classification:\")\n",
    "print(np.unique(xgb_labels))\n",
    "print(\"_____________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12576158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels for Autoencoder Classification:\n",
      "[0 1]\n",
      "_____________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dataset.loc[dataset[' Label'] == 'BENIGN', ' Label'] = 0  # Saldırılar için 1 normaller için 0 değeri verme\n",
    "dataset.loc[dataset[' Label'] != 0, ' Label'] = 1\n",
    "autoencoder_labels = dataset[' Label'].copy()\n",
    "print(\"Labels for Autoencoder Classification:\")\n",
    "print(np.unique(autoencoder_labels))\n",
    "print(\"_____________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f12481e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataseti X ve Y ayırma\n",
    "x = dataset.drop(' Label', axis=1)\n",
    "y = np.c_[autoencoder_labels, xgb_labels]\n",
    "# Normal ve anomali ayırma\n",
    "x_normal = x[y == 0]\n",
    "x_anomaly = x[y == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c82389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder Train-Test datası ayırma\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,\n",
    "                                                    y,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=12345,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4e9a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = preprocessing.StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "y_xgb = y_test[:, 1]\n",
    "y_test = y_test[:, 0]\n",
    "y_train = y_train[:, 0]\n",
    "x_train = x_train[y_train == 0]\n",
    "y_train = y_train[y_train == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd755940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 16:21:33.448586: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Autoencoder\n",
    "input = tf.keras.layers.Input(shape=(78,))\n",
    "encoder = tf.keras.Sequential([\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu')])(input)\n",
    "decoder = tf.keras.Sequential([\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(78, activation='sigmoid')])(encoder)\n",
    "autoencoder = tf.keras.Model(inputs=input, outputs=decoder)\n",
    "autoencoder.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e14063d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder Training...\n",
      "Epoch 1/11\n",
      "66996/72683 [==========================>...] - ETA: 3s - loss: 0.6171"
     ]
    }
   ],
   "source": [
    "# Autoencoder eğitme\n",
    "print(\"Autoencoder Training...\")\n",
    "history = autoencoder.fit(x_train, x_train,\n",
    "                          epochs=11,\n",
    "                          batch_size=20,\n",
    "                          validation_split=0.2,\n",
    "                          shuffle=True)\n",
    "print(\"Training Complete.\")\n",
    "print(\"_____________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d77ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test datasını reconstruct etme\n",
    "reconstruct = autoencoder.predict(x_test)\n",
    "print(\"_____________________________________________________________________\")\n",
    "reconstruct_loss = tf.keras.losses.mse(reconstruct, x_test)\n",
    "threshold = np.percentile(reconstruct_loss, 85)\n",
    "print(\"Threshold: \", threshold)\n",
    "print(\"_____________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ca27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data, threshold):\n",
    "    # reconstructions = model(data)\n",
    "    reconstructions = model.predict(data)\n",
    "    loss = tf.keras.losses.mse(reconstructions, data)\n",
    "    prediction = []\n",
    "    for i in range(len(loss)):\n",
    "        if loss[i] >= threshold:\n",
    "            prediction.append(1)\n",
    "        else:\n",
    "            prediction.append(0)\n",
    "    prediction = np.array(prediction)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def print_stats(predictions, labels):\n",
    "    print(\"Accuracy = {}\".format(accuracy_score(labels, predictions)))\n",
    "    print(\"Precision = {}\".format(precision_score(labels, predictions)))\n",
    "    print(\"Recall = {}\".format(recall_score(labels, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa0e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(autoencoder, x_test, threshold)\n",
    "print(\"Preds:\")\n",
    "print(preds[0:10])\n",
    "print(\"y_test:\")\n",
    "print(y_test[0:10])\n",
    "print(\"Model Stats: \")\n",
    "print(\"_____________________________________________________________________\")\n",
    "print_stats(preds.astype(bool), y_test.astype(bool))\n",
    "print(\"_____________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e57d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost data hazırlama\n",
    "xgb_x = []\n",
    "xgb_y = []\n",
    "for i in range(len(x_test)):\n",
    "    if preds[i] == 1 and y_xgb[i] != 0:\n",
    "        xgb_x.append(x_test[i, :])\n",
    "        xgb_y.append(y_xgb[i])\n",
    "xgb_x = np.array(xgb_x)\n",
    "xgb_y = np.array(xgb_y)\n",
    "\n",
    "a = le.inverse_transform(xgb_y)\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "xgb_y = le2.fit_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a31d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(xgb_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e854d0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(xgb_x, xgb_y,\n",
    "                                                        test_size=0.25,\n",
    "                                                        random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3bf21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_predictor = xgb.XGBClassifier(n_estimators=100,\n",
    "                                     max_depth=1, learning_rate=0.2, verbosity=0,\n",
    "                                     objective='multi:softmax',\n",
    "                                     use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424c1e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"XGBoost Cross Validation...\")\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, random_state=12345)\n",
    "n_scores = cross_val_score(attack_predictor, x_train2, y_train2, scoring='accuracy',\n",
    "                           cv=cv, error_score='raise')\n",
    "print(\"CV Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea0e0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "print(\"____________________________________________ \\n \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c2b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"XGBoost Training...\")\n",
    "attack_predictor.fit(x_train2, y_train2)\n",
    "print(\"Training Complete.\")\n",
    "attack_preds = attack_predictor.predict(x_test2)\n",
    "\n",
    "attack_predictor.score(x_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cf0b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Attack Type Classification\")\n",
    "print(\"\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test2, attack_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ba0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test2, attack_preds))\n",
    "print(\"____________________________________________ \\n \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c472a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.unique(y_test2)\n",
    "a = le2.inverse_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765edbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = a\n",
    "conf_matrix = confusion_matrix(y_test2, attack_preds)\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS,\n",
    "            yticklabels=LABELS, annot=True, fmt=\"d\")\n",
    "plt.title(\"Attack Type Classification\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d0a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pickling Models...\")\n",
    "pickle.dump(scaler, open('scaler.pkl', 'wb'))\n",
    "pickle.dump(autoencoder, open('autoencoder.pkl', 'wb'))\n",
    "pickle.dump(attack_predictor, open('attack_predictor.pkl', 'wb'))\n",
    "print(\"Pickle Complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
