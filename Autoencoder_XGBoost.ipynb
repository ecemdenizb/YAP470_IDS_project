{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9742300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: scikit-learn\r\n",
      "Version: 1.2.0\r\n",
      "Summary: A set of python modules for machine learning and data mining\r\n",
      "Home-page: http://scikit-learn.org\r\n",
      "Author: \r\n",
      "Author-email: \r\n",
      "License: new BSD\r\n",
      "Location: /Users/boramert/opt/anaconda3/lib/python3.9/site-packages\r\n",
      "Requires: joblib, numpy, scipy, threadpoolctl\r\n",
      "Required-by: pyod, scikit-learn-intelex\r\n"
     ]
    }
   ],
   "source": [
    "!pip show scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "245d38ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/boramert/opt/anaconda3/lib/python3.9/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faa04bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boramert/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras import regularizers, Sequential\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26e08d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelencoder(ds):\n",
    "    encoded_ds=ds.copy()\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for col in encoded_ds.select_dtypes(include=['object']).columns:\n",
    "        encoded_ds[col]=le.fit_transform(encoded_ds[col])\n",
    "    \n",
    "    return encoded_ds\n",
    "\n",
    "def encoding_for_anomalous(ds):\n",
    "    encoded_ds=ds.copy()\n",
    "    for i in range(len(ds)):\n",
    "        if encoded_ds.iloc[i]=='BENIGN':\n",
    "            encoded_ds.iloc[i]= 0\n",
    "        else:\n",
    "            encoded_ds.iloc[i]= 1\n",
    "            \n",
    "    return encoded_ds  \n",
    "\n",
    "def scaling(ds):\n",
    "    scaler=preprocessing.StandardScaler()\n",
    "    scaled_ds=scaler.fit_transform(ds)\n",
    "    return scaled_ds\n",
    "\n",
    "def drop_infs(ds):\n",
    "    ds.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    ds.dropna(how='any', inplace=True)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8337c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None,\n",
    "             \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3584a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a936441",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=drop_infs(dataset)\n",
    "y=dataset[' Label']\n",
    "x=dataset.drop(' Label', axis=1)\n",
    "x_scaled=scaling(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dda2a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1741839\n",
       "1     556556\n",
       "Name:  Label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "102d3d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_normal = x_scaled[y == 0]\n",
    "x_anomaly = x_scaled[y == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a72f16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 22:38:49.180642: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "x_normal_train = np.asarray(x_normal).astype(np.float32)\n",
    "\n",
    "x_normal_train = tf.cast(x_normal_train, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d45882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(Dense(32,  activation='relu', input_shape=(78,)))\n",
    "autoencoder.add(Dense(16,  activation='relu'))\n",
    "autoencoder.add(Dense(8,    activation='linear', name=\"Compressed\"))\n",
    "autoencoder.add(Dense(16,  activation='relu'))\n",
    "autoencoder.add(Dense(32,  activation='relu'))\n",
    "autoencoder.add(Dense(78,  activation='sigmoid'))\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49148ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "21773/21773 [==============================] - 19s 825us/step - loss: 0.7424 - val_loss: 0.3437\n",
      "Epoch 2/10\n",
      "21773/21773 [==============================] - 20s 927us/step - loss: 0.7361 - val_loss: 0.3433\n",
      "Epoch 3/10\n",
      "21773/21773 [==============================] - 17s 780us/step - loss: 0.7357 - val_loss: 0.3436\n",
      "Epoch 4/10\n",
      "21773/21773 [==============================] - 17s 776us/step - loss: 0.7355 - val_loss: 0.3433\n",
      "Epoch 5/10\n",
      "21773/21773 [==============================] - 17s 778us/step - loss: 0.7353 - val_loss: 0.3433\n",
      "Epoch 6/10\n",
      "21773/21773 [==============================] - 17s 774us/step - loss: 0.7352 - val_loss: 0.3432\n",
      "Epoch 7/10\n",
      "21773/21773 [==============================] - 17s 777us/step - loss: 0.7351 - val_loss: 0.3430\n",
      "Epoch 8/10\n",
      "21773/21773 [==============================] - 18s 832us/step - loss: 0.7350 - val_loss: 0.3429\n",
      "Epoch 9/10\n",
      "21773/21773 [==============================] - 19s 857us/step - loss: 0.7349 - val_loss: 0.3429\n",
      "Epoch 10/10\n",
      "21773/21773 [==============================] - 17s 783us/step - loss: 0.7349 - val_loss: 0.3429\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(x_normal_train, \n",
    "                          x_normal_train, \n",
    "                          batch_size=64,     \n",
    "                          epochs=10, \n",
    "                          verbose=1, \n",
    "                          validation_split = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02a9fc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(autoencoder.input, autoencoder.get_layer('Compressed').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1685463f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54433/54433 [==============================] - 19s 342us/step\n",
      "17393/17393 [==============================] - 6s 331us/step\n"
     ]
    }
   ],
   "source": [
    "encoded_normal = encoder.predict(x_normal)\n",
    "encoded_anomaly = encoder.predict(x_anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10c59ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_x = np.append(encoded_normal, encoded_anomaly, axis = 0)\n",
    "normal_y = np.zeros(encoded_normal.shape[0])\n",
    "anomaly_y = np.ones(encoded_anomaly.shape[0])\n",
    "encoded_y = np.append(normal_y, anomaly_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4857dc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(encoded_x, encoded_y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63a26670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.2-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /Users/boramert/opt/anaconda3/lib/python3.9/site-packages (from xgboost) (1.7.3)\n",
      "Requirement already satisfied: numpy in /Users/boramert/opt/anaconda3/lib/python3.9/site-packages (from xgboost) (1.21.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f7bd7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV, ElasticNet, LassoCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f25ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBClassifier(n_estimators=380, max_depth=2, learning_rate=0.2)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model_xgb, x_train, y_train, scoring='accuracy', cv=cv, error_score='raise')\n",
    "\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014c03d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb.fit(x_train, y_train)\n",
    "xgb_preds = model_xgb.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ac88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab38b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"\")\n",
    "print (\"Classification Report: \")\n",
    "print (classification_report(YVal, xgb_preds))\n",
    "\n",
    "print (\"\")\n",
    "print (\"Accuracy Score: \", accuracy_score(y_val, xgb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055448f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f6d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['Normal', 'Fraud'] \n",
    "conf_matrix = confusion_matrix(y_val, xgb_preds) \n",
    "plt.figure(figsize =(12, 12)) \n",
    "sns.heatmap(conf_matrix, xticklabels = LABELS,  \n",
    "            yticklabels = LABELS, annot = True, fmt =\"d\"); \n",
    "plt.title(\"Confusion matrix\") \n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcd56e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
